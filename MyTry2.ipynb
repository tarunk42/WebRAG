{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b78b17-17cf-4294-8b67-24d917ebd4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tarunkashyap/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tarunkashyap/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cda5645-7793-489f-9930-1860cf43bee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/tarunkashyap/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tarunkashyap/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking started. Navigate your Firefox browser as usual.\n",
      "Captured content for URL: about:blank\n",
      "Captured content for URL: https://www.google.com/\n",
      "Captured content for URL: https://www.google.com/search?q=neele+kabootar&sca_esv=4f7cc8aad04de26a&source=hp&ei=u84LZ_HEIJSohbIPjbGByAs&iflsig=AL9hbdgAAAAAZwvcyxi3tfLyPcJ7gVtWTrWGE9RJNqyI&oq=neele+kaboota&gs_lp=Egdnd3Mtd2l6Ig1uZWVsZSBrYWJvb3RhKgIIADIFEAAYgAQyCBAAGIAEGKIEMggQABiABBiiBDIIEAAYgAQYogQyCBAAGKIEGIkFSJgmUNkEWJkbcAF4AJABAJgBc6AByQiqAQM5LjS4AQPIAQD4AQGYAg6gAoYJqAIKwgIQEAAYAxjlAhjqAhiMAxiPAcICEBAuGAMY5QIY6gIYjAMYjwHCAhEQLhiABBixAxjRAxiDARjHAcICCxAAGIAEGLEDGIMBwgIOEC4YgAQYsQMYgwEYigXCAgsQLhiABBjRAxjHAcICCxAuGIAEGLEDGIMBwgIIEC4YgAQYsQPCAg4QLhiABBixAxiDARjUAsICCBAAGIAEGLEDwgILEC4YgAQYxwEYrwHCAgUQLhiABMICDRAuGIAEGNEDGMcBGArCAhEQLhiABBjHARiYBRiaBRivAcICBxAAGIAEGArCAgcQLhiABBgKmAMGkgcDOS41oAeEgQE&sclient=gws-wiz\n",
      "Captured content for URL: https://www.google.com/search?q=idaho&sca_esv=4f7cc8aad04de26a&ei=w84LZ5K-N9WGhbIPtbu38QU&ved=0ahUKEwjSq_PdvouJAxVVQ0EAHbXdLV4Q4dUDCA8&uact=5&oq=idaho&gs_lp=Egxnd3Mtd2l6LXNlcnAiBWlkYWhvMggQLhiABBixAzIFEAAYgAQyCBAAGIAEGLEDMgUQABiABDIFEAAYgAQyCBAAGIAEGLEDMg4QLhiABBjHARiOBRivATIIEAAYgAQYsQMyBRAuGIAEMgsQABiABBixAxiDATIXEC4YgAQYsQMYlwUY3AQY3gQY4ATYAQJI0DxQ8jNYoTtwAXgBkAEAmAG7AaAB1gSqAQMyLjO4AQPIAQD4AQGYAgagAosFqAIKwgIWEAAYAxi0AhjlAhjqAhiMAxiPAdgBAcICFhAuGAMYtAIY5QIY6gIYjAMYjwHYAQHCAgsQABiABBiRAhiKBcICCxAuGIAEGJECGIoFwgIREC4YgAQYsQMY0QMYgwEYxwHCAg4QABiABBixAxiDARiKBcICDhAuGIAEGLEDGMcBGK8BwgIOEC4YgAQYsQMY0QMYxwHCAh0QLhiABBixAxjHARivARiXBRjcBBjeBBjgBNgBAsICCxAuGIAEGLEDGIMBmAMJugYECAEYCroGBggCEAEYFJIHAzIuNKAHlGo&sclient=gws-wiz-serp\n",
      "Captured content for URL: https://www.amazon.co.uk/\n",
      "Captured content for URL: https://www.amazon.co.uk/s?k=electric+toothbrush&crid=1VYV7V2UA5OVK&sprefix=electric+%2Caps%2C88&ref=nb_sb_ss_w_hit-vc-lth_electric-toothbrush_k0_1_9\n",
      "Captured content for URL: https://www.amazon.co.uk/Oral-B-Electric-Toothbrush-Pressure-Whitening/dp/B094VJV3PS/ref=sr_1_5?crid=1VYV7V2UA5OVK&dib=eyJ2IjoiMSJ9.KNRfii_kk7uuSQOQtoPEv5dWUDrYurTRvML3pNjStyck5_NMM300nuOPZIIireKoIqb2CR-tWNAJPXCpbjmNKIjwc2EUDo__0fp_NfPU53yaGzDuZIFp3WnTP34xmfoBa19RS5xMHQdeeG-yPXeMqNrOpFHz9El1qjaYBgBYZ0SaGf_Ns1yGpy-UvbIB-6ZUhc-owyI8HoSZOGAGBcXg82P0TZcRqDsP4CR9mmokGEMZaLDu4pxvYmTpwPtyNNvovKNWL4Y043TBj_VzLcCm6A574QyktnGm332LgnnlAzI.l4A9CJ-IJ8ywpNl8kfaDgI5iIQJnzwq8m0nzVSA2A7g&dib_tag=se&keywords=electric%2Btoothbrush&qid=1728827108&sprefix=electric%2B%2Caps%2C88&sr=8-5&th=1\n",
      "Browser window closed.\n",
      "Data saved to page_test6.json and browser session closed.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set up Firefox WebDriver\n",
    "service = Service(executable_path=\"/opt/homebrew/bin/geckodriver\")\n",
    "driver = webdriver.Firefox(service=service)\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to extract search query from the URL\n",
    "def extract_search_query(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "\n",
    "    search_query = query_params.get('q') or query_params.get('query') or query_params.get('k')\n",
    "    if search_query:\n",
    "        return search_query[0]  # Return the first match\n",
    "\n",
    "    # Extract search query from URLs with search terms in the path (e.g., Amazon)\n",
    "    match = re.search(r'/s\\?k=([^&]+)', url)\n",
    "    if match:\n",
    "        return unquote(match.group(1))\n",
    "\n",
    "    return None\n",
    "\n",
    "# Function to tokenize and remove stop words from text\n",
    "def process_text(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words and word.isalnum()]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Function to track activity and content\n",
    "def track_activity_with_content():\n",
    "    page_data = []\n",
    "\n",
    "    try:\n",
    "        print(\"Tracking started. Navigate your Firefox browser as usual.\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Wait for the page to load\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "                \n",
    "                page_url = driver.current_url\n",
    "                page_title = driver.title\n",
    "\n",
    "                # Get the text content of the page (visible text only)\n",
    "                page_text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "\n",
    "                # Process the page text by tokenizing and removing stop words\n",
    "                processed_text = process_text(page_text)\n",
    "\n",
    "                # Get the current date and time\n",
    "                capture_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                # Extract search query from the URL (if any)\n",
    "                search_query = extract_search_query(page_url)\n",
    "\n",
    "                # Create a dictionary with the captured data\n",
    "                entry = {\n",
    "                    \"url\": page_url,\n",
    "                    \"title\": page_title,\n",
    "                    \"text\": processed_text,\n",
    "                    \"capture_time\": capture_time,\n",
    "                    \"search_query\": search_query if search_query else \"No search query\"\n",
    "                }\n",
    "\n",
    "                # If the current URL is new, add it to the list\n",
    "                if not page_data or page_data[-1]['url'] != page_url:\n",
    "                    page_data.append(entry)\n",
    "                    print(f\"Captured content for URL: {page_url}\")\n",
    "\n",
    "            except NoSuchWindowException:\n",
    "                # Break the loop if the browser window is closed\n",
    "                print(\"Browser window closed.\")\n",
    "                break\n",
    "\n",
    "            # Throttle checks to reduce performance impact\n",
    "            time.sleep(5)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Tracking stopped by user.\")\n",
    "\n",
    "    finally:\n",
    "        # Save tracked data to a JSON file\n",
    "        with open('page_test6.json', 'w') as f:\n",
    "            json.dump(page_data, f, indent=4)\n",
    "\n",
    "        driver.quit()\n",
    "        print(\"Data saved to page_test6.json and browser session closed.\")\n",
    "\n",
    "# Open a blank tab to start tracking\n",
    "driver.get('about:blank')\n",
    "\n",
    "# Start tracking\n",
    "track_activity_with_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bf816-7495-442e-b688-dc7c7c8a44ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
